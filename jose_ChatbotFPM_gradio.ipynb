{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JoseTayllan/ChatbotFPM-Gradio/blob/main/jose_ChatbotFPM_gradio.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# üíº Faculdade de Princ√≠pios Militares ‚Äì FPM  \n",
        "### üìö Curso de Sistemas de Informa√ß√£o\n",
        "\n",
        "---\n",
        "\n",
        "**Disciplina:** Intelig√™ncia Artificial Aplicada  \n",
        "**Projeto:** Chatbot Institucional com Gradio + IA (Unify)  \n",
        "**Professor:**  Dr.Jonas Augusto Kunzler  \n",
        "**Aluno:** Jos√© Tayllan Pinto Almeida\n",
        "**Per√≠odo:** 2025/1  \n",
        "**Data de Entrega:** 15/06/2025\n",
        "\n",
        "---\n",
        "# ü§ñ Chatbot Institucional da FPM ‚Äì Sentinela Caveira\n",
        "\n",
        "Este notebook implementa um **assistente virtual inteligente** para a Faculdade de Princ√≠pios Militares (FPM), com o objetivo de:\n",
        "\n",
        "- Automatizar o atendimento √†s d√∫vidas frequentes de alunos e interessados;\n",
        "- Oferecer uma interface acess√≠vel e personalizada via Gradio;\n",
        "- Permitir atualiza√ß√£o din√¢mica da base de conhecimento pela secretaria;\n",
        "- Integrar modelos de linguagem avan√ßados (como Claude/GPT via UnifyAI) com fallback inteligente.\n",
        "\n",
        "---\n",
        "\n",
        "## üìÇ Componentes principais do projeto\n",
        "\n",
        "- `ChatBot`: classe central com l√≥gica de resposta, mem√≥ria de conversa e integra√ß√£o com IA.\n",
        "- `gradio_chatbot_interface()`: interface interativa para usu√°rios em ambiente web.\n",
        "- `painel_secretaria()`: painel administrativo para registrar novas respostas manualmente.\n",
        "- `base_conhecimento_manual.json`: base local com perguntas/respostas validadas.\n",
        "- `perguntas_sem_resposta.json`: log de perguntas que n√£o foram respondidas pela base.\n",
        "\n",
        "---\n",
        "\n",
        "## üë• P√∫blico-alvo\n",
        "\n",
        "- Estudantes e interessados na FPM\n",
        "- Equipe da secretaria e coordena√ß√£o\n",
        "- Professores e avaliadores do projeto\n"
      ],
      "metadata": {
        "id": "wolPM-mO-Zwv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## üì¶ 1. Instala√ß√£o de depend√™ncias\n",
        "Instala os pacotes necess√°rios para execu√ß√£o da interface e conex√£o com modelos de linguagem."
      ],
      "metadata": {
        "id": "8qwjL11n-dOv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Install the Unify package"
      ],
      "metadata": {
        "id": "pZdlOjy2gn8x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install unifyai"
      ],
      "metadata": {
        "id": "fQbCLMylCNPO",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## üìö 2. Importa√ß√£o de bibliotecas e configura√ß√£o inicial\n",
        "Importa bibliotecas padr√£o para interface, manipula√ß√£o de arquivos e integra√ß√£o com o modelo Unify."
      ],
      "metadata": {
        "id": "cx8v9tLO-mCe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Install the Gradio package"
      ],
      "metadata": {
        "id": "l5EaG6aIgd6x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gradio"
      ],
      "metadata": {
        "collapsed": true,
        "id": "9Fruxe0Ogbho"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Chatbot Interface"
      ],
      "metadata": {
        "id": "7QfwxwbHH0Wv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "import json\n",
        "from pathlib import Path\n",
        "from typing import Optional\n",
        "from unify import  Unify # Cliente para modelos de linguagem (Claude, GPT, etc.)\n",
        "import gradio as gr      # Interface de usu√°rio via navegador\n",
        "\n",
        "# =============================\n",
        "# üß† MAPA DE SIN√îNIMOS\n",
        "# =============================\n",
        "\n",
        "# Mapeia sin√¥nimos comuns para facilitar correspond√™ncia de perguntas com a base\n",
        "VARIACOES = {\n",
        "    \"mensalidade\": [\"pre√ßo\", \"valor\", \"custo\"],\n",
        "    \"curso\": [\"gradua√ß√£o\", \"forma√ß√£o\", \"faculdade\", \"√°rea de estudo\"],\n",
        "    \"hor√°rio\": [\"funcionamento\", \"hora\", \"atendimento\"],\n",
        "    \"contato\": [\"telefone\", \"whatsapp\", \"falar com algu√©m\"],\n",
        "    \"local\": [\"endere√ßo\", \"fica onde\", \"localiza√ß√£o\"],\n",
        "    \"bolsa\": [\"desconto\", \"isen√ß√£o\", \"benef√≠cio\"]\n",
        "}\n",
        "\n",
        "# ========================================\n",
        "# üîç FUN√á√ÉO DE NORMALIZA√á√ÉO DE INTEN√á√ïES\n",
        "# ========================================\n",
        "def normalizar_pergunta_com_variacoes(pergunta_usuario: str) -> Optional[str]:\n",
        "    \"\"\"\n",
        "    Identifica o tema principal da pergunta com base em palavras-chave\n",
        "    e seus sin√¥nimos definidos no dicion√°rio VARIACOES.\n",
        "    \"\"\"\n",
        "    pergunta_lower = pergunta_usuario.lower()\n",
        "    for chave, sinonimos in VARIACOES.items():\n",
        "        if chave in pergunta_lower:\n",
        "            return chave\n",
        "        for sinonimo in sinonimos:\n",
        "            if sinonimo in pergunta_lower:\n",
        "                return chave\n",
        "    return None\n",
        "\n",
        "# =============================\n",
        "# ü§ñ CLASSE PRINCIPAL DO CHATBOT\n",
        "# =============================\n",
        "class ChatBot:\n",
        "\n",
        "    def __init__(self,\n",
        "        api_key: Optional[str] = \"Chave do Seu Modelo\",\n",
        "        endpoint: Optional[str] = \"claude-3.5-sonnet@vertex-ai\",\n",
        "        model: Optional[str] = None,\n",
        "        provider: Optional[str] = None\n",
        "    ) -> None:\n",
        "        \"\"\"\n",
        "        Inicializa o ChatBot com cliente Unify, hist√≥rico e base de conhecimento.\n",
        "        \"\"\"\n",
        "        self._message_history = []\n",
        "        self._paused = False\n",
        "        self._client = Unify(\n",
        "            api_key=api_key,\n",
        "            endpoint=endpoint,\n",
        "            model=model,\n",
        "            provider=provider,\n",
        "        )\n",
        "        self.manual_knowledge = self._load_knowledge_bases()\n",
        "\n",
        "    def _load_knowledge_bases(self):\n",
        "        \"\"\"\n",
        "        Carrega as bases de conhecimento dos arquivos JSON.\n",
        "        D√° prioridade √† base manual.\n",
        "        \"\"\"\n",
        "        def carregar(path_str):\n",
        "            path = Path(path_str)\n",
        "            if path.exists():\n",
        "                with path.open(\"r\", encoding=\"utf-8\") as f:\n",
        "                    return {\n",
        "                        item[\"pergunta\"].strip().lower(): item[\"resposta\"]\n",
        "                        for item in json.load(f)\n",
        "                    }\n",
        "            return {}\n",
        "\n",
        "        manual = carregar(\"base_conhecimento_manual.json\")\n",
        "        scrap = carregar(\"base_conhecimento_scrap.json\")\n",
        "        exemplos = carregar(\"base_exemplos_fpm.json\")\n",
        "        return {**scrap, **manual, **exemplos}  # prioridade para manual\n",
        "\n",
        "    def recarregar_base_manual(self):\n",
        "        \"\"\"\n",
        "        Recarrega a base de conhecimento manual (sem reiniciar o bot).\n",
        "        \"\"\"\n",
        "        self.manual_knowledge = self._load_knowledge_bases()\n",
        "\n",
        "    @property\n",
        "    def client(self) -> str:\n",
        "        \"\"\"\n",
        "        Exposi√ß√£o do cliente Unify.\n",
        "        \"\"\"\n",
        "        return self._client\n",
        "\n",
        "    def _get_credits(self):\n",
        "        \"\"\"\n",
        "        Retorna os cr√©ditos restantes na API.\n",
        "        \"\"\"\n",
        "        return self._client.get_credit_balance()\n",
        "\n",
        "    def _registrar_pergunta_sem_resposta(self, pergunta: str, origem: str = \"manual\"):\n",
        "        \"\"\"\n",
        "        Registra perguntas que n√£o foram encontradas na base manual/scrap/json,\n",
        "        ou foram respondidas pela IA, mas precisam de verifica√ß√£o posterior.\n",
        "        \"\"\"\n",
        "        path = Path(\"perguntas_sem_resposta.json\")\n",
        "        try:\n",
        "            if path.exists():\n",
        "                with path.open(\"r\", encoding=\"utf-8\") as f:\n",
        "                    dados = json.load(f)\n",
        "            else:\n",
        "                dados = []\n",
        "\n",
        "            dados.append({\n",
        "                \"pergunta\": pergunta.strip(),\n",
        "                \"timestamp\": str(Path().stat().st_mtime),\n",
        "                \"origem\": origem\n",
        "            })\n",
        "\n",
        "            with path.open(\"w\", encoding=\"utf-8\") as f:\n",
        "                json.dump(dados, f, ensure_ascii=False, indent=2)\n",
        "        except Exception as e:\n",
        "            print(f\"[ERRO ao registrar pergunta n√£o respondida]: {e}\")\n",
        "\n",
        "    def _process_input(self, inp: str, show_credits: bool, show_provider: bool):\n",
        "        \"\"\"\n",
        "        Processa a entrada do usu√°rio, respondendo com base:\n",
        "        1. Na base manual;\n",
        "        2. Nas varia√ß√µes sem√¢nticas;\n",
        "        3. No modelo de IA (Unify) se n√£o encontrou resposta.\n",
        "        \"\"\"\n",
        "        pergunta = inp.strip().lower()\n",
        "\n",
        "        # 1. Verifica√ß√£o direta na base manual\n",
        "        if pergunta in self.manual_knowledge:\n",
        "            resposta = self.manual_knowledge[pergunta]\n",
        "            self._update_message_history(\"user\", inp)\n",
        "            self._update_message_history(\"assistant\", resposta)\n",
        "            yield resposta\n",
        "            return\n",
        "\n",
        "        # 2. Verifica√ß√£o com sin√¥nimos\n",
        "        termo = normalizar_pergunta_com_variacoes(pergunta)\n",
        "        if termo:\n",
        "            for base_pergunta, resposta in self.manual_knowledge.items():\n",
        "                if termo in base_pergunta:\n",
        "                    self._update_message_history(\"user\", inp)\n",
        "                    self._update_message_history(\"assistant\", resposta)\n",
        "                    yield resposta\n",
        "                    return\n",
        "\n",
        "        # 3. REGISTRO da pergunta sem resposta\n",
        "        self._registrar_pergunta_sem_resposta(inp)\n",
        "\n",
        "        # 4. IA da Unify responde com liberdade\n",
        "        self._message_history = [{\n",
        "            \"role\": \"system\",\n",
        "            \"content\": '''\n",
        "\n",
        "            Voc√™ √© o Sentinela Caveira, assistente virtual oficial da Faculdade de Princ√≠pios Militares (FPM), localizada em Goi√¢nia - GO.\n",
        "\n",
        "           Foque exclusivamente nas informa√ß√µes da FPM. Nunca mencione outras institui√ß√µes como Pit√°goras, Unip, Anhanguera, etc.\n",
        "\n",
        "           Sobre a FPM:\n",
        "           - Primeira faculdade particular com tradi√ß√£o militar do pa√≠s.\n",
        "           - Iniciou atividades em 2017, j√° com conceito 4 no MEC e corpo docente de refer√™ncia.\n",
        "           - Localizada na Rua 10, n¬∫ 923 ‚Äì Setor Oeste, Goi√¢nia ‚Äì GO.\n",
        "           - WhatsApp: (62) 9 99994-0063\n",
        "           - Site: https://www.faculdadepm.edu.br\n",
        "           - Hor√°rio de atendimento: das 08h √†s 21h.\n",
        "\n",
        "          Cursos atualmente oferecidos:\n",
        "          - Biomedicina\n",
        "          - Educa√ß√£o F√≠sica\n",
        "          - Enfermagem\n",
        "          - Gest√£o da Tecnologia da Informa√ß√£o\n",
        "\n",
        "          Administra√ß√£o e Coordena√ß√£o:\n",
        "          - Prof. Andr√© Costa ‚Äì Marketing e P√≥s-gradua√ß√£o\n",
        "           Prof. Marcelo ‚Äì Jur√≠dico\n",
        "          - Prof. Renato Ribeiro ‚Äì Gradua√ß√£o\n",
        "          - Prof¬™. M√°rcia ‚Äì Secretariado Acad√™mico\n",
        "\n",
        "          Estrutura:\n",
        "          - Laborat√≥rios pr√≥prios equipados para aulas pr√°ticas\n",
        "          - Academia Fitness Center\n",
        "          - Est√°gios junto √† Academia da Pol√≠cia Militar\n",
        "          - Parcerias com outras institui√ß√µes\n",
        "\n",
        "          Miss√£o:\n",
        "          Agregar valores de civismo e cidadania mediante a disciplina e os valores humanos, formando profissionais √©ticos, inovadores e transformadores da sociedade, com foco na excel√™ncia do conhecimento e compromisso social.\n",
        "\n",
        "          Valores:\n",
        "          1. Disciplina\n",
        "          2. Respeito\n",
        "          3. Civismo\n",
        "          4. Cidadania\n",
        "          5. √âtica\n",
        "\n",
        "          Objetivos:\n",
        "          1. Preservar civismo e cidadania com base militar\n",
        "          2. Desenvolver conhecimento para o Centro-Oeste\n",
        "          3. Formar profissionais humanos e t√©cnicos\n",
        "          4. Integrar com a comunidade por meio de ci√™ncia, cultura e tecnologia\n",
        "          5. Capacitar continuamente docentes e equipe t√©cnica\n",
        "          6. Estimular interc√¢mbio com institui√ß√µes nacionais e internacionais\n",
        "          7. Formar gestores com base em excel√™ncia e planejamento\n",
        "          8. Garantir inclus√£o de PCDs com educa√ß√£o igualit√°ria\n",
        "          9. Assegurar qualidade em a√ß√µes administrativas e acad√™micas\n",
        "          10. Ser refer√™ncia em ensino, pesquisa e extens√£o com impacto social\n",
        "\n",
        "          Se n√£o souber a resposta, diga:\n",
        "          ‚ÄúEssa informa√ß√£o n√£o est√° dispon√≠vel no momento. Por favor, entre em contato pelo WhatsApp da FPM.‚Äù\n",
        "          '''\n",
        "\n",
        "\n",
        "        }]\n",
        "        self._update_message_history(\"user\", inp)\n",
        "        initial_credit_balance = self._get_credits()\n",
        "        self._registrar_pergunta_sem_resposta(inp, origem=\"IA\")\n",
        "        stream = self._client.generate(messages=self._message_history, stream=True)\n",
        "        response = \"\"\n",
        "        for chunk in stream:\n",
        "            response += chunk\n",
        "            yield chunk\n",
        "        self._update_message_history(\"assistant\", response)\n",
        "        if show_credits:\n",
        "            print(f\"\\n(spent {initial_credit_balance - self._get_credits():.6f} credits)\")\n",
        "        if show_provider:\n",
        "            print(f\"\\n(provider: {self._client.provider})\")\n",
        "\n",
        "    def _update_message_history(self, role: str, content: str):\n",
        "        \"\"\"\n",
        "        Atualiza o hist√≥rico com a nova mensagem.\n",
        "        \"\"\"\n",
        "        self._message_history.append({\n",
        "            \"role\": role,\n",
        "            \"content\": content,\n",
        "        })\n",
        "\n",
        "    def clear_chat_history(self):\n",
        "        \"\"\"\n",
        "        Limpa todo o hist√≥rico da conversa.\n",
        "        \"\"\"\n",
        "        self._message_history.clear()\n",
        "\n",
        "    def run(self, show_credits: bool = False, show_provider: bool = False):\n",
        "        \"\"\"\n",
        "        Modo interativo no terminal (√∫til para testes locais).\n",
        "        \"\"\"\n",
        "        if not self._paused:\n",
        "            print(\"Let's have a chat. (Enter `pause` to pause and `quit` to exit)\")\n",
        "            self.clear_chat_history()\n",
        "        else:\n",
        "            print(\"Welcome back! (Remember, enter `pause` to pause and `quit` to exit)\")\n",
        "        self._paused = False\n",
        "        while True:\n",
        "            inp = input(\"> \")\n",
        "            if inp == \"quit\":\n",
        "                self.clear_chat_history()\n",
        "                break\n",
        "            elif inp == \"pause\":\n",
        "                self._paused = True\n",
        "                break\n",
        "            for word in self._process_input(inp, show_credits, show_provider):\n",
        "                print(word, end=\"\", flush=True)\n",
        "            print()\n",
        "\n",
        "    def chat(self, inp: str, show_credits: bool = False, show_provider: bool = False):\n",
        "        \"\"\"\n",
        "        Executa uma conversa e retorna a resposta como string.\n",
        "        Usado na integra√ß√£o com Gradio.\n",
        "        \"\"\"\n",
        "        return ''.join(self._process_input(inp, show_credits, show_provider))\n"
      ],
      "metadata": {
        "id": "8t8L1k2Gn7_B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr\n",
        "\n",
        "def gradio_chatbot_interface():\n",
        "    bot = ChatBot()\n",
        "\n",
        "    def respond(message, history):\n",
        "        response = \"\"\n",
        "        for chunk in bot._process_input(message, show_credits=False, show_provider=False):\n",
        "            response += chunk\n",
        "            yield history + [(message, response)]\n",
        "\n",
        "        bot._update_message_history(\"assistant\", response)\n",
        "\n",
        "    with gr.Blocks() as demo:\n",
        "        gr.Markdown(\"# Chat com Sentinela Caveira\")\n",
        "        chatbot = gr.Chatbot()\n",
        "        msg = gr.Textbox(placeholder=\"Digite sua mensagem aqui...\", lines=4)\n",
        "        clear = gr.Button(\"Limpar\")\n",
        "\n",
        "        def clear_chat():\n",
        "            bot.clear_chat_history()\n",
        "            return []\n",
        "\n",
        "        msg.submit(respond, [msg, chatbot], chatbot)\n",
        "        clear.click(clear_chat, None, chatbot)\n",
        "\n",
        "    demo.launch()\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    gradio_chatbot_interface()\n"
      ],
      "metadata": {
        "id": "0iftOfTUHgoP",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ‚ñ∂Ô∏è 5. Execu√ß√£o do Chatbot\n",
        "Inicializa a interface gr√°fica se o notebook for executado como script principal."
      ],
      "metadata": {
        "id": "XexCQJZM-4KO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr\n",
        "from datetime import datetime\n",
        "import os\n",
        "import json\n",
        "\n",
        "def gradio_chatbot_interface():\n",
        "    \"\"\"\n",
        "    Inicializa a interface visual do Chatbot da FPM com Gradio.\n",
        "    Inclui funcionalidades como:\n",
        "    - Envio e exibi√ß√£o de mensagens no estilo chat\n",
        "    - Tema escuro/claro\n",
        "    - Bot√µes de sugest√£o\n",
        "    - Registro de perguntas n√£o respondidas\n",
        "    \"\"\"\n",
        "    bot = ChatBot()  # Inst√¢ncia do ChatBot\n",
        "    theme_mode = gr.State(\"light\")  # Estado de tema: claro ou escuro\n",
        "\n",
        "    # ----------------------------------------------------------------------\n",
        "    # Fun√ß√£o auxiliar: registra localmente perguntas sem resposta na base\n",
        "    # ----------------------------------------------------------------------\n",
        "    def salvar_pergunta_sem_resposta(pergunta):\n",
        "        caminho = \"perguntas_sem_resposta.json\"\n",
        "        nova = {\n",
        "            \"pergunta\": pergunta,\n",
        "            \"data\": datetime.now().isoformat()\n",
        "        }\n",
        "\n",
        "        if os.path.exists(caminho):\n",
        "            with open(caminho, \"r\", encoding=\"utf-8\") as f:\n",
        "                perguntas = json.load(f)\n",
        "        else:\n",
        "            perguntas = []\n",
        "\n",
        "        perguntas.append(nova)\n",
        "\n",
        "        with open(caminho, \"w\", encoding=\"utf-8\") as f:\n",
        "            json.dump(perguntas, f, indent=2, ensure_ascii=False)\n",
        "\n",
        "    # ----------------------------------------------------------------------\n",
        "    # Fun√ß√£o principal: responde a uma mensagem do usu√°rio\n",
        "    # ----------------------------------------------------------------------\n",
        "    def respond(message, history):\n",
        "        \"\"\"\n",
        "        Processa a entrada do usu√°rio:\n",
        "        - Tenta responder com a base manual\n",
        "        - Se n√£o encontrar, envia √† IA da Unify\n",
        "        - Mostra \"digitando...\" enquanto aguarda\n",
        "        - Salva perguntas n√£o respondidas\n",
        "        \"\"\"\n",
        "        response = \"\"\n",
        "        fallback_msg = (\n",
        "            \"üéì Essa informa√ß√£o ainda n√£o est√° no meu banco de dados. \"\n",
        "            \"Por favor, entre em contato com a FPM pelo WhatsApp: (62) 9 99994-0063.\"\n",
        "        )\n",
        "        yield history + [(f\"üë§ {message}\", \"üéì Digitando resposta...\")], \"\"\n",
        "\n",
        "        try:\n",
        "            # Gera√ß√£o por IA (streaming)\n",
        "            for chunk in bot._process_input(message, show_credits=False, show_provider=False):\n",
        "                response += chunk\n",
        "                yield history + [(f\"üë§ {message}\", f\"üéì {response}\")], \"\"\n",
        "\n",
        "            # Verifica se resposta foi √∫til ou vazia\n",
        "            if not response.strip() or \"essa informa√ß√£o\" in response.lower():\n",
        "                yield history + [(f\"üë§ {message}\", fallback_msg)], \"\"\n",
        "                salvar_pergunta_sem_resposta(message)\n",
        "            else:\n",
        "                bot._update_message_history(\"assistant\", response)\n",
        "\n",
        "        except Exception:\n",
        "            yield history + [(f\"üë§ {message}\", fallback_msg)], \"\"\n",
        "            salvar_pergunta_sem_resposta(message)\n",
        "\n",
        "    # ----------------------------------------------------------------------\n",
        "    # Limpa o hist√≥rico do chat\n",
        "    # ----------------------------------------------------------------------\n",
        "    def clear_chat():\n",
        "        bot.clear_chat_history()\n",
        "        return [], \"\"\n",
        "\n",
        "    # ----------------------------------------------------------------------\n",
        "    # Altern√¢ncia entre tema claro e escuro\n",
        "    # ----------------------------------------------------------------------\n",
        "    def toggle_theme(mode):\n",
        "        return \"dark\" if mode == \"light\" else \"light\"\n",
        "\n",
        "    # ----------------------------------------------------------------------\n",
        "    # BLOCO GRADIO - Interface visual customizada\n",
        "    # ----------------------------------------------------------------------\n",
        "    with gr.Blocks(css=\"\"\"<-- CSS customizado para responsividade e estilo -->\"\"\") as demo:\n",
        "\n",
        "        # Cabe√ßalho institucional com logomarca da FPM\n",
        "        gr.HTML(\"\"\"\n",
        "        <div style=\"text-align: center; margin-bottom: 20px;\">\n",
        "            <img src=\"https://faculdadepm.edu.br/wp-content/uploads/2025/01/fpm.jpeg\" height=\"60\">\n",
        "            <h1 style=\"color:#003366; margin-top: 10px;\">Assistente Virtual da FPM</h1>\n",
        "            <p style=\"color:#333; font-size: 1rem; max-width: 600px; margin: 0 auto\">\n",
        "                Seja bem-vindo! Sou o Sentinela Caveira, assistente virtual da Faculdade de Princ√≠pios Militares.\n",
        "                Em que posso te ajudar hoje?\n",
        "            </p>\n",
        "        </div>\n",
        "        \"\"\")\n",
        "\n",
        "        # Componente de chat vis√≠vel\n",
        "        chatbot = gr.Chatbot()\n",
        "\n",
        "        # Linha de bot√µes r√°pidos\n",
        "        with gr.Row():\n",
        "            cursos_btn = gr.Button(\"üéì Cursos\", variant=\"secondary\")\n",
        "            bolsas_btn = gr.Button(\"üéØ Bolsas\", variant=\"secondary\")\n",
        "            contato_btn = gr.Button(\"üìû Contato\", variant=\"secondary\")\n",
        "            toggle_btn = gr.Button(\"üåô Modo Escuro\")\n",
        "\n",
        "        # Campo de texto para mensagens\n",
        "        msg = gr.Textbox(\n",
        "            placeholder=\"Digite sua mensagem aqui...\",\n",
        "            lines=3,\n",
        "            label=\"Sua mensagem\",\n",
        "            show_label=False,\n",
        "            autofocus=True\n",
        "        )\n",
        "\n",
        "        # Linha com bot√µes de envio e limpeza\n",
        "        with gr.Row():\n",
        "            send_btn = gr.Button(\"Enviar\", variant=\"primary\")\n",
        "            clear_btn = gr.Button(\"Limpar conversa\")\n",
        "\n",
        "        # Triggers dos bot√µes e do enter\n",
        "        msg.submit(respond, [msg, chatbot], [chatbot, msg])\n",
        "        send_btn.click(respond, [msg, chatbot], [chatbot, msg])\n",
        "        clear_btn.click(clear_chat, None, [chatbot, msg])\n",
        "\n",
        "        # Bot√µes r√°pidos populam mensagem automaticamente\n",
        "        cursos_btn.click(lambda: \"Quais cursos a FPM oferece?\", None, msg)\n",
        "        bolsas_btn.click(lambda: \"Quais bolsas e descontos est√£o dispon√≠veis?\", None, msg)\n",
        "        contato_btn.click(lambda: \"Como entro em contato com a FPM?\", None, msg)\n",
        "        toggle_btn.click(toggle_theme, theme_mode, theme_mode)\n",
        "\n",
        "    # Inicializa a interface no navegador\n",
        "    demo.launch()\n",
        "\n",
        "# Permite rodar como script\n",
        "if __name__ == \"__main__\":\n",
        "    gradio_chatbot_interface()\n"
      ],
      "metadata": {
        "id": "djOlKY_JEfuZ",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Teste Automatizado."
      ],
      "metadata": {
        "id": "LwtwE7cg-6c2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import unittest\n",
        "\n",
        "class TestChatBotFPM(unittest.TestCase):\n",
        "    def setUp(self):\n",
        "        self.bot = ChatBot()\n",
        "\n",
        "    def ask(self, question: str) -> str:\n",
        "        return self.bot.chat(question)\n",
        "\n",
        "    def test_cursos_oferecidos(self):\n",
        "        resposta = self.ask(\"Quais cursos a FPM oferece?\")\n",
        "        self.assertIn(\"Biomedicina\", resposta)\n",
        "        self.assertIn(\"Educa√ß√£o F√≠sica\", resposta)\n",
        "        self.assertNotIn(\"Medicina\", resposta)\n",
        "\n",
        "    def test_nome_correto_da_fpm(self):\n",
        "        resposta = self.ask(\"FPM √© a Pit√°goras?\")\n",
        "        self.assertIn(\"Faculdade de Princ√≠pios Militares\", resposta)\n",
        "        self.assertNotIn(\"Pit√°goras\", resposta)\n",
        "\n",
        "    def test_horario_atendimento(self):\n",
        "        resposta = self.ask(\"Qual √© o hor√°rio de atendimento?\")\n",
        "        self.assertIn(\"08h √†s 21h\", resposta)\n",
        "\n",
        "    def test_endereco(self):\n",
        "        resposta = self.ask(\"Onde fica localizada a FPM?\")\n",
        "        self.assertIn(\"Rua 10\", resposta)\n",
        "        self.assertIn(\"Setor Oeste\", resposta)\n",
        "\n",
        "    def test_fallback_info_desconhecida(self):\n",
        "        resposta = self.ask(\"Quantas salas de aula tem a FPM?\")\n",
        "        self.assertTrue(\"n√£o est√° dispon√≠vel\" in resposta.lower() or \"entre em contato\" in resposta.lower())\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    unittest.main(argv=[''], exit=False)\n"
      ],
      "metadata": {
        "id": "hcti-usfo5rv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr\n",
        "import json\n",
        "from datetime import datetime\n",
        "\n",
        "# =============================\n",
        "# üîß Configura√ß√µes e arquivos\n",
        "# =============================\n",
        "\n",
        "PERGUNTAS_FILE = \"perguntas_sem_resposta.json\"\n",
        "BASE_MANUAL_FILE = \"base_conhecimento_manual.json\"\n",
        "USUARIO_CORRETO = \"admin\"\n",
        "SENHA_CORRETA = \"1234\"\n",
        "\n",
        "# =============================\n",
        "# üì• Utilit√°rios de carregamento\n",
        "# =============================\n",
        "\n",
        "def carregar_perguntas():\n",
        "    \"\"\"\n",
        "    L√™ o arquivo de perguntas sem resposta e retorna:\n",
        "    - A lista de objetos JSON\n",
        "    - Um dicion√°rio com o texto da pergunta como chave e √≠ndice como valor\n",
        "    \"\"\"\n",
        "    try:\n",
        "        with open(PERGUNTAS_FILE, \"r\", encoding=\"utf-8\") as f:\n",
        "            perguntas = json.load(f)\n",
        "    except FileNotFoundError:\n",
        "        perguntas = []\n",
        "\n",
        "    perguntas_dict = {\n",
        "        f\"{i+1} - {p['pergunta'].strip()} [origem: {p.get('origem', 'manual')}]\": i\n",
        "        for i, p in enumerate(perguntas)\n",
        "    }\n",
        "\n",
        "    return perguntas, perguntas_dict\n",
        "\n",
        "def salvar_perguntas(perguntas):\n",
        "    \"\"\"\n",
        "    Salva a lista atualizada de perguntas sem resposta.\n",
        "    Remove as que foram respondidas.\n",
        "    \"\"\"\n",
        "    with open(PERGUNTAS_FILE, \"w\", encoding=\"utf-8\") as f:\n",
        "        json.dump(perguntas, f, indent=2, ensure_ascii=False)\n",
        "\n",
        "def adicionar_na_base_manual(pergunta, resposta, origem=\"manual\"):\n",
        "    \"\"\"\n",
        "    Adiciona uma nova pergunta + resposta na base de conhecimento manual.\n",
        "    Inclui data e origem.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        with open(BASE_MANUAL_FILE, \"r\", encoding=\"utf-8\") as f:\n",
        "            base = json.load(f)\n",
        "    except FileNotFoundError:\n",
        "        base = []\n",
        "\n",
        "    nova_entrada = {\n",
        "        \"pergunta\": pergunta.strip(),\n",
        "        \"resposta\": resposta.strip(),\n",
        "        \"origem\": origem,\n",
        "        \"data_adicionada\": datetime.now().isoformat()\n",
        "    }\n",
        "    base.append(nova_entrada)\n",
        "\n",
        "    with open(BASE_MANUAL_FILE, \"w\", encoding=\"utf-8\") as f:\n",
        "        json.dump(base, f, indent=2, ensure_ascii=False)\n",
        "\n",
        "# =============================\n",
        "# üßë‚Äçüíª Interface Painel Secretaria\n",
        "# =============================\n",
        "\n",
        "def painel_secretaria():\n",
        "    \"\"\"\n",
        "    Interface administrativa protegida por login.\n",
        "    Permite √† secretaria responder perguntas pendentes e atualiz√°-las na base.\n",
        "    \"\"\"\n",
        "\n",
        "    def autenticar(usuario, senha):\n",
        "        \"\"\"Verifica usu√°rio e senha fixos\"\"\"\n",
        "        return usuario == USUARIO_CORRETO and senha == SENHA_CORRETA\n",
        "\n",
        "    perguntas, perguntas_dict = carregar_perguntas()\n",
        "\n",
        "    def salvar_resposta(pergunta_selecionada, resposta):\n",
        "        \"\"\"\n",
        "        Salva a resposta fornecida para uma pergunta selecionada\n",
        "        e move a pergunta da lista pendente para a base manual.\n",
        "        \"\"\"\n",
        "        if pergunta_selecionada not in perguntas_dict:\n",
        "            return \"‚ùå Nenhuma pergunta selecionada\"\n",
        "\n",
        "        indice = perguntas_dict[pergunta_selecionada]\n",
        "        perguntas[indice][\"resposta\"] = resposta\n",
        "        perguntas[indice][\"respondida_em\"] = datetime.now().isoformat()\n",
        "\n",
        "        origem = perguntas[indice].get(\"origem\", \"manual\")\n",
        "        adicionar_na_base_manual(perguntas[indice][\"pergunta\"], resposta, origem)\n",
        "\n",
        "        perguntas_ativas = [p for p in perguntas if \"resposta\" not in p]\n",
        "        salvar_perguntas(perguntas_ativas)\n",
        "\n",
        "        return f\"‚úÖ Resposta salva com sucesso para: {pergunta_selecionada}\"\n",
        "\n",
        "    def carregar_resposta(pergunta_selecionada):\n",
        "        \"\"\"\n",
        "        Carrega resposta existente, se houver, e exibe status:\n",
        "        - Pendente\n",
        "        - Respondida\n",
        "        \"\"\"\n",
        "        if pergunta_selecionada not in perguntas_dict:\n",
        "            return \"\", \"‚ùå Pergunta n√£o encontrada\"\n",
        "\n",
        "        pergunta_obj = perguntas[perguntas_dict[pergunta_selecionada]]\n",
        "        resposta_existente = pergunta_obj.get(\"resposta\", \"\")\n",
        "\n",
        "        try:\n",
        "            with open(BASE_MANUAL_FILE, \"r\", encoding=\"utf-8\") as f:\n",
        "                base_manual = json.load(f)\n",
        "            for item in base_manual:\n",
        "                if item[\"pergunta\"].strip().lower() == pergunta_obj[\"pergunta\"].strip().lower():\n",
        "                    resposta_existente = item[\"resposta\"]\n",
        "                    break\n",
        "        except FileNotFoundError:\n",
        "            pass\n",
        "\n",
        "        origem = pergunta_obj.get(\"origem\", \"manual\")\n",
        "        status_msg = (\n",
        "            f\"‚úÖ Respondida [origem: {origem.upper()}]\"\n",
        "            if resposta_existente else\n",
        "            f\"‚è≥ Pendente [origem: {origem.upper()}]\"\n",
        "        )\n",
        "        return resposta_existente, status_msg\n",
        "\n",
        "    # ==============\n",
        "    # Interface Gradio\n",
        "    # ==============\n",
        "    with gr.Blocks() as demo:\n",
        "        login_sucesso = gr.State(False)\n",
        "\n",
        "        # Tela de login\n",
        "        with gr.Column(visible=True) as login_col:\n",
        "            gr.Markdown(\"### Login da Secretaria\")\n",
        "            usuario_input = gr.Textbox(label=\"Usu√°rio\")\n",
        "            senha_input = gr.Textbox(label=\"Senha\", type=\"password\")\n",
        "            login_status = gr.Textbox(label=\"Status de Login\", interactive=False)\n",
        "            login_btn = gr.Button(\"Entrar\")\n",
        "\n",
        "        # Painel administrativo ap√≥s login\n",
        "        with gr.Column(visible=False) as painel_col:\n",
        "            gr.Markdown(\"# Painel da Secretaria - Responder Perguntas Pendentes\")\n",
        "            dropdown = gr.Dropdown(label=\"Pergunta pendente\", choices=list(perguntas_dict.keys()))\n",
        "            resposta_input = gr.Textbox(label=\"Sua resposta\", lines=5, placeholder=\"Digite a resposta completa aqui...\")\n",
        "            resultado = gr.Textbox(label=\"Status\", interactive=False)\n",
        "            btn = gr.Button(\"Salvar resposta\")\n",
        "\n",
        "            btn.click(salvar_resposta, [dropdown, resposta_input], resultado)\n",
        "            dropdown.change(carregar_resposta, inputs=[dropdown], outputs=[resposta_input, resultado])\n",
        "\n",
        "        # Valida√ß√£o de login\n",
        "        def tentar_login(usuario, senha):\n",
        "            if autenticar(usuario, senha):\n",
        "                return gr.update(visible=False), \"\", gr.update(visible=True)\n",
        "            else:\n",
        "                return gr.update(visible=True), \"‚ùå Usu√°rio ou senha incorretos\", gr.update(visible=False)\n",
        "\n",
        "        login_btn.click(tentar_login, [usuario_input, senha_input], [login_col, login_status, painel_col])\n",
        "\n",
        "    demo.launch()\n",
        "\n",
        "# Executa a interface se chamado como script\n",
        "if __name__ == \"__main__\":\n",
        "    painel_secretaria()\n"
      ],
      "metadata": {
        "id": "WzZG_nH_0GUq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# üå± Melhorias e Implementa√ß√µes Futuras\n",
        "\n",
        "1. **üîê Autentica√ß√£o com m√∫ltiplos usu√°rios e n√≠veis de acesso**\n",
        "   - Cadastro de usu√°rios diferentes (secretaria, coordena√ß√£o, TI)\n",
        "   - Controle de permiss√µes por fun√ß√£o\n",
        "\n",
        "2. **üìä Dashboard de Estat√≠sticas**\n",
        "   - Quantidade de perguntas respondidas por dia/semana\n",
        "   - Quais t√≥picos s√£o mais perguntados (ex: cursos, bolsas, contato)\n",
        "\n",
        "3. **üîé Busca inteligente por perguntas similares**\n",
        "   - Sistema de sugest√£o autom√°tica ao digitar\n",
        "   - Uso de embeddings para compara√ß√£o sem√¢ntica\n",
        "\n",
        "4. **üì§ Exporta√ß√£o de dados**\n",
        "   - Download das perguntas sem resposta (.csv ou .xlsx)\n",
        "   - Exporta√ß√£o da base manual para backup ou migra√ß√£o\n",
        "\n",
        "5. **üß† Aprendizado cont√≠nuo**\n",
        "   - Atualiza√ß√£o autom√°tica da base manual com base em aprova√ß√µes humanas\n",
        "   - Treinamento incremental com base nos logs\n",
        "\n",
        "6. **üó£Ô∏è Suporte a voz**\n",
        "   - Entrada por microfone (STT)\n",
        "   - Resposta falada (TTS)\n",
        "\n",
        "7. **üì± Vers√£o mobile amig√°vel**\n",
        "   - Adapta√ß√£o de layout responsivo com foco em uso por celular\n",
        "   - PWA (Progressive Web App) para acesso como app\n",
        "\n",
        "8. **üîÅ Integra√ß√£o com WhatsApp ou Telegram**\n",
        "   - Conex√£o com API oficial do WhatsApp Business\n",
        "   - Canal alternativo de atendimento com mesma IA\n",
        "\n",
        "9. **üìÇ Categoriza√ß√£o e filtros**\n",
        "   - Classifica√ß√£o autom√°tica das perguntas (ex: curso, bolsa, estrutura)\n",
        "   - Filtros no painel da secretaria para facilitar gest√£o\n",
        "\n",
        "10. **üåê Modo multil√≠ngue**\n",
        "    - Suporte a portugu√™s-ingl√™s (tradutor autom√°tico)\n",
        "    - Detec√ß√£o autom√°tica de idioma\n",
        "\n",
        "---\n",
        "\n",
        "üìå *Essas ideias abrem caminho para transformar o assistente virtual da FPM em uma plataforma inteligente de atendimento educacional, com foco em automa√ß√£o, efici√™ncia e inova√ß√£o institucional.*\n",
        "\n",
        "\n",
        "## Responsavel: Jos√© Tayllan Pinto Almeida"
      ],
      "metadata": {
        "id": "La_dc8jzBTB6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install selenium\n",
        "\n"
      ],
      "metadata": {
        "id": "XyVk0gcz4cDM",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Tentativa se Scrap Inteligente, Abordagem sem sucesso"
      ],
      "metadata": {
        "id": "2Av1CwAi9jsf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from selenium import webdriver\n",
        "from selenium.webdriver.chrome.options import Options\n",
        "from bs4 import BeautifulSoup\n",
        "import json\n",
        "from datetime import datetime\n",
        "\n",
        "# Carrega as URLs relevantes\n",
        "with open(\"urls_relevantes_fpm.json\", \"r\", encoding=\"utf-8\") as f:\n",
        "    urls = json.load(f)\n",
        "\n",
        "output_file = \"base_conhecimento_scrap.json\"\n",
        "\n",
        "options = Options()\n",
        "options.add_argument(\"--headless\")\n",
        "options.add_argument(\"--disable-gpu\")\n",
        "options.add_argument(\"--no-sandbox\")\n",
        "\n",
        "driver = webdriver.Chrome(options=options)\n",
        "\n",
        "qa_pairs = []\n",
        "\n",
        "def limpar(texto):\n",
        "    return \" \".join(texto.replace(\"\\xa0\", \" \").replace(\"\\n\", \" \").split())\n",
        "\n",
        "def extrair_qa_por_url(url):\n",
        "    driver.get(url)\n",
        "    soup = BeautifulSoup(driver.page_source, \"html.parser\")\n",
        "    blocos = soup.find_all([\"p\", \"li\", \"h1\", \"h2\", \"h3\"])\n",
        "\n",
        "    texto = \" \".join([limpar(b.get_text()) for b in blocos if len(b.get_text().strip()) > 30])\n",
        "    titulo = soup.title.string.strip().lower() if soup.title else \"\"\n",
        "\n",
        "    perguntas = []\n",
        "    respostas = []\n",
        "\n",
        "    # Cursos de gradua√ß√£o\n",
        "    if \"graduacao\" in url:\n",
        "        perguntas.append(\"Quais cursos de gradua√ß√£o a FPM oferece?\")\n",
        "        cursos = [li.get_text(strip=True) for li in soup.find_all(\"li\") if len(li.get_text()) < 100 and \"curso\" in li.get_text().lower()]\n",
        "        respostas.append(\", \".join(set(cursos)) if cursos else texto)\n",
        "\n",
        "    # P√≥s-gradua√ß√£o\n",
        "    elif \"pos\" in url:\n",
        "        perguntas.append(\"Quais cursos de p√≥s-gradua√ß√£o a FPM oferece?\")\n",
        "        cursos = [h.get_text(strip=True) for h in soup.find_all(\"h3\") if \"MBA\" in h.get_text() or \"p√≥s\" in h.get_text().lower()]\n",
        "        respostas.append(\", \".join(set(cursos)) if cursos else texto)\n",
        "\n",
        "    # Contato\n",
        "    elif \"fale-conosco\" in url or \"quem-somos\" in url:\n",
        "        perguntas.append(\"Qual o endere√ßo da FPM?\")\n",
        "        respostas.append(texto)\n",
        "        perguntas.append(\"Qual o telefone ou WhatsApp da FPM?\")\n",
        "        contatos = [a.get(\"href\") for a in soup.find_all(\"a\", href=True) if \"tel:\" in a[\"href\"] or \"wa.me\" in a[\"href\"]]\n",
        "        respostas.append(\", \".join(contatos) if contatos else texto)\n",
        "\n",
        "    # Miss√£o e valores\n",
        "    elif \"nossos-valores\" in url:\n",
        "        perguntas.append(\"Quais s√£o os valores da FPM?\")\n",
        "        respostas.append(texto)\n",
        "\n",
        "    elif \"responsabilidade-social\" in url:\n",
        "        perguntas.append(\"Quais a√ß√µes sociais a FPM realiza?\")\n",
        "        respostas.append(texto)\n",
        "\n",
        "    elif \"estrutura\" in url:\n",
        "        perguntas.append(\"Como √© a estrutura da FPM?\")\n",
        "        respostas.append(texto)\n",
        "\n",
        "    elif \"calendario\" in url:\n",
        "        perguntas.append(\"Onde encontro o calend√°rio acad√™mico da FPM?\")\n",
        "        respostas.append(texto)\n",
        "\n",
        "    elif \"faq\" in url:\n",
        "        perguntas.append(\"Quais s√£o as d√∫vidas frequentes da FPM?\")\n",
        "        respostas.append(texto)\n",
        "\n",
        "    elif \"noticias\" in url:\n",
        "        perguntas.append(\"O que h√° de novo na FPM?\")\n",
        "        respostas.append(texto)\n",
        "\n",
        "    else:\n",
        "        perguntas.append(f\"O que diz a p√°gina: {titulo}?\")\n",
        "        respostas.append(texto)\n",
        "\n",
        "    for pergunta, resposta in zip(perguntas, respostas):\n",
        "        qa_pairs.append({\n",
        "            \"categoria\": url.split(\"/\")[3] if len(url.split(\"/\")) > 3 else \"geral\",\n",
        "            \"pergunta\": pergunta.strip().lower(),\n",
        "            \"resposta\": limpar(resposta),\n",
        "            \"origem_url\": url,\n",
        "            \"capturado_em\": datetime.now().isoformat()\n",
        "        })\n",
        "\n",
        "# Roda para cada URL\n",
        "for u in urls:\n",
        "    extrair_qa_por_url(u)\n",
        "\n",
        "driver.quit()\n",
        "\n",
        "# Salvar em JSON\n",
        "with open(output_file, \"w\", encoding=\"utf-8\") as f:\n",
        "    json.dump(qa_pairs, f, ensure_ascii=False, indent=2)\n",
        "\n",
        "print(f\"‚úÖ {len(qa_pairs)} perguntas/respostas geradas em {output_file}\")"
      ],
      "metadata": {
        "id": "SrN-KqMX79De"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.download(\"base_conhecimento_scrap.json\")\n"
      ],
      "metadata": {
        "id": "hD1GoNaD8FUG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "\n",
        "url = \"https://faculdadepm.edu.br/calendario-academico/\"\n",
        "r = requests.get(url)\n",
        "print(r.text[:3000])  # Ver os primeiros 3000 caracteres do HTML\n",
        "\n"
      ],
      "metadata": {
        "id": "IXLg1eKb8ktv",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##capturar links ocultos de PDF\n"
      ],
      "metadata": {
        "id": "SdQYyFGW00Td"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from selenium import webdriver\n",
        "from selenium.webdriver.chrome.options import Options\n",
        "import tempfile\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "# Criar diret√≥rio tempor√°rio para evitar conflitos de perfil\n",
        "temp_dir = tempfile.mkdtemp()\n",
        "\n",
        "options = Options()\n",
        "options.add_argument(\"--headless\")\n",
        "options.add_argument(f\"--user-data-dir={temp_dir}\")\n",
        "options.add_argument(\"--disable-gpu\")\n",
        "options.add_argument(\"--no-sandbox\")\n",
        "\n",
        "driver = webdriver.Chrome(options=options)\n",
        "\n",
        "url = \"https://faculdadepm.edu.br/\"\n",
        "driver.get(url)\n",
        "\n",
        "html = driver.page_source\n",
        "soup = BeautifulSoup(html, \"html.parser\")\n",
        "\n",
        "# Tentar encontrar links e iframes\n",
        "print(\"\\n=== Links encontrados ===\")\n",
        "for a in soup.find_all(\"a\", href=True):\n",
        "    print(a[\"href\"])\n",
        "\n",
        "print(\"\\n=== iFrames encontrados ===\")\n",
        "for iframe in soup.find_all(\"iframe\"):\n",
        "    print(iframe.get(\"src\"))\n",
        "\n",
        "driver.quit()\n"
      ],
      "metadata": {
        "id": "H6VoTcBR0209"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}